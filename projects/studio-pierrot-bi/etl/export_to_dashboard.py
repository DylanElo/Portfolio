import sqlite3
import json
import os
from datetime import datetime
from pathlib import Path

# Configuration
DB_PATH = Path(__file__).parent.parent / 'studio_pierrot.db'
OUTPUT_PATH = Path(__file__).parent.parent / 'dashboard' / 'data.js'

def get_latest_data():
    """Query warehouse for latest anime metrics"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Query latest metrics from fact_anime_metrics
    query = '''
    SELECT 
        a.mal_id as id,
        a.title,
        'TV' as type,
        a.episodes,
        'Finished Airing' as status,
        m.score,
        m.members,
        m.favorites,
        m.rank,
        a.start_date as aired_from,
        m.scored_by,
        m.popularity,
        'Unknown' as rating
    FROM fact_anime_metrics m
    JOIN dim_anime a ON m.anime_id = a.anime_id
    ORDER BY m.score DESC
    '''
    
    cursor.execute(query)
    rows = cursor.fetchall()
    
    # Convert to list of dicts
    data = []
    for row in rows:
        item = dict(row)
        item['image_url'] = ''  # Placeholder for future
        item['url'] = f"https://myanimelist.net/anime/{item['id']}"
        data.append(item)
        
    conn.close()
    return data

def export_to_js(data):
    """Write data to JS file"""
    timestamp = datetime.now().isoformat()
    js_content = f"// Auto-generated by etl/export_to_dashboard.py on {timestamp}\n"
    js_content += f"// Source: SQLite Warehouse ({DB_PATH})\n"
    js_content += f"export const lastUpdated = '{timestamp}';\n"
    js_content += "export const animeData = " + json.dumps(data, indent=2) + ";\n"
    
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        f.write(js_content)
    
    print(f"✅ Exported {len(data)} records to {OUTPUT_PATH}")

if __name__ == '__main__':
    if not os.path.exists(DB_PATH):
        print(f"❌ Database not found: {DB_PATH}")
    else:
        data = get_latest_data()
        if data:
            export_to_js(data)
